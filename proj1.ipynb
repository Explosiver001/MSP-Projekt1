{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projekt MSP1 / 2024\n",
    "Cílem tohoto projektu je se seznámit s programovými nástroji využívaných ve statistice a osvojit si základní procedury. Projekt není primárně zaměřen na efektivitu využívání programového vybavení (i když úplně nevhodné konstrukce mohou mít vliv na hodnocení), ale nejvíce nás zajímají vaše statistické závěry a způsob vyhodnocení. Dbejte také na to, že každý graf musí splňovat nějaké podmínky - přehlednost, čitelnost, popisky.\n",
    "\n",
    "V projektu budete analyzovat časy běhu šesti různých konfigurací algoritmů. Ke každé konfiguraci vzniklo celkem 200 nezávislých běhů, jejichž logy máte k dispozici v souboru [logfiles.zip](logfiles.zip).\n",
    "\n",
    "Pokud nemáte rozchozené prostředí pro pro spouštění Jupyter notebooku, můžete využití službu [Google Colab](https://colab.google/). Jakákoliv spolupráce, sdílení řešení a podobně je zakázána!\n",
    "\n",
    "S případnými dotazy se obracejte na Vojtěcha Mrázka (mrazek@fit.vutbr.cz).\n",
    "\n",
    "__Odevzdání:__ tento soubor (není potřeba aby obsahoval výstupy skriptů) do neděle 27. 10. 2024 v IS VUT. Kontrola bude probíhat na Pythonu 3.12.3 (standardní instalace Ubuntu); neočekává se však to, že byste používali nějaké speciality a nekompatibilní knihovny. V případě nesouladu verzí a podobných problémů budete mít možnost reklamace a prokázání správnosti funkce. Bez vyplnění vašich komentářů a závěrů do označených buněk nebude projekt hodnocen!\n",
    "\n",
    "__Upozornění:__ nepřidávejte do notebooku další buňky, odpovídejte tam, kam se ptáme (textové komentáře do Markdown buněk)\n",
    "\n",
    "__Tip:__ před odevzdáním resetujte celý notebook a zkuste jej spustit od začátku. Zamezíte tak chybám krokování a editací, kdy výsledek z buňky na konci použijete na začátku."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__OTÁZKA K DOPLNĚNÍ:__\n",
    "\n",
    "Michal Novák (xnovak3g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Načtení potřebných knihoven\n",
    "Načtěte knihovny, které jsou nutné pro zpracování souborů a práci se statistickými funkcemi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import json\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Načtení dat do DataFrame\n",
    "Ze souboru `logfiles.zip` umístěném ve stejném adresáři načtěte data a vytvořte Pandas DataFrame.\n",
    "\n",
    "Výsledky jsou uložené ve formátu JSON - pro zpracování použijte knihovnu `json`.\n",
    "Můžete využít následující kostru - je vhodné pracovat přímo se ZIP souborem. Jedinou nevýhodou může být to, že vám bude vracet _byte_ objekt, který musíte přes funkci `decode` zpracovat.\n",
    "\n",
    "Upravte také pomocí funkce `.astype()` datové typy patřičných sloupců.\n",
    "\n",
    "```py\n",
    "data = []\n",
    "with ZipFile(\"logfiles.zip\") as zf:\n",
    "    for filename in zf.namelist():\n",
    "        # TODO test názvu souboru\n",
    "        with zf.open(filename, \"r\") as f:\n",
    "            pass # vytvořte slovník\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init empty list\n",
    "data = []\n",
    "\n",
    "# open zip file\n",
    "with ZipFile(\"logfiles.zip\") as zf:\n",
    "    # browse all files\n",
    "    for filename in zf.namelist():\n",
    "        # read only json files\n",
    "        if filename.endswith('.json'):\n",
    "            with zf.open(filename, \"r\") as f:\n",
    "                # read file contents, parse json to dict and save to list\n",
    "                data.append(json.loads(f.read().decode()))\n",
    "\n",
    "# convert list to dataframe\n",
    "df = pd.DataFrame(data)\n",
    "# set types\n",
    "df = df.astype({'run': int, 'runtime': float})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analýza a čištění dat\n",
    "Vhodným způsobem pro všechny konfigurace analyzujte časy běhů a pokud tam jsou, identifikujte hodnoty, které jsou chybné. Vyberte vhodný graf, který zobrazí samostatně jednotlivé konfigurace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use interquartile range to find 'outliers'\n",
    "# compute values for each configuration\n",
    "runtimes = df[['configuration','runtime']].groupby('configuration')\n",
    "q1 = runtimes.quantile(0.25)\n",
    "q3 = runtimes.quantile(0.75)\n",
    "irq = q3 - q1\n",
    "\n",
    "lower_bound = q1 - 1.5 * irq\n",
    "upper_bound = q3 + 1.5 * irq\n",
    "\n",
    "# add computed lower and upper bounds to dataframe (create copy of original dataframe)\n",
    "df = df.join(lower_bound, on='configuration', rsuffix='_lower')\n",
    "df = df.join(upper_bound, on='configuration', rsuffix='_upper')\n",
    "\n",
    "# print out outliers\n",
    "display(df[(df['runtime'] < df['runtime_lower']) | (df['runtime'] > df['runtime_upper'])])\n",
    "\n",
    "# plot\n",
    "df[[\"runtime\",\"configuration\"]].plot.box(\"configuration\", xlabel='Configuration', ylabel=\"Runtime\")\n",
    "plt.title(\"Runtimes for each configuration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__OTÁZKA K DOPLNĚNÍ:__\n",
    "\n",
    "_Objevily se nějaké chybné hodnoty? Proč tam jsou s ohledem na to, že se jedná o běhy algoritmů? Proč jste zvolili tento typ grafu?_\n",
    "\n",
    "Chybné hodnoty se objevily. Většinou se jedná o běhy, které skončily statusem \"SEGFAULT\" nebo \"TIME LIMIT\", ale vyskytly se i některé se statusem \"SUCCESS\".\n",
    "- TIME LIMIT - zde se mohlo například jednat o zacyklení algoritmu v \"nekonečné smyčce\", nebo čekání na událost, která nenastala\n",
    "- SEGFAULT - chybný přístup do paměti (mimo hranice vyhrazené paměti), pravděpodobně neošetřený vstup\n",
    "- SUCCESS - pravděpodobně chyba v algoritmu, která se projevuje specifickým vstupem - zkracuje nebo prolužuje dobu běhu\n",
    "\n",
    "Zvolený graf je tzv. boxplot (krabicový graf). V boxplotu můžeme vizualizovat data pomocí kvartilů. Zároveň tak můžeme pozorovat i chybné hodnoty (odlehlé prvky), které leží pod prvním kvartilem (vespod), nebo nad třetím kvartilem (nahoře).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vyčistěte dataframe `df` tak, aby tam tyto hodnoty nebyly a ukažte znovu analýzu toho, že čištění dat bylo úspěšné. Odtud dále pracujte s vyčištěným datasetem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter dataframe (remove outliers)\n",
    "df = df[(df['runtime'] >= df['runtime_lower']) & (df['runtime'] <= df['runtime_upper'])]\n",
    "# remove added columns\n",
    "df.drop(['runtime_lower', 'runtime_upper'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deskriptivní popis hodnot\n",
    "Vypište pro jednotlivé konfigurace základní deskriptivní parametry.  \n",
    "\n",
    "__TIP__ pokud výsledky uložíte jako Pandas DataFrame, zobrazí se v tabulce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe data \n",
    "df.groupby('configuration')['runtime'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__OTÁZKA K DOPLNĚNÍ:__\n",
    "\n",
    "_Okomentujte, co všechno můžeme z parametrů vyčíst._\n",
    "\n",
    "Z tabulky lze pořadě vyčíst: \n",
    "- count: počet nechybných běhů pro každou konfiguraci\n",
    "- mean: průměrnou hodnotu běhů pro danou konfiguraci\n",
    "- std: směrodatnou odchylku běhů pro danou konfiguraci\n",
    "- min, max: minimální a maximální hodnota běhů pro danou konfiguraci\n",
    "- 25%: první kvartil\n",
    "- 50%: medián (druhý kvartil)\n",
    "- 75%: třetí kvartil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizualizace\n",
    "Vizualizujte časy běhů algoritmů tak, aby byl v jednom grafu zřejmý i rozptyl hodnot, avšak bylo možné porovnání. Zvolte vhodný graf, který pak níže komentujte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots()\n",
    "\n",
    "sns.violinplot(data=df.groupby('configuration')['runtime'].apply(list).to_dict(), ax=axes)\n",
    "\n",
    "axes.set_title('Runtimes for each configuration')\n",
    "axes.yaxis.grid(True)\n",
    "axes.set_xlabel('Configuration')\n",
    "axes.set_ylabel('Runtime')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__OTÁZKA K DOPLNĚNÍ:__\n",
    "\n",
    "_Okomentujte  výsledky z tabulky._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Určení efektivity konfigurací algoritmů\n",
    "Nás ale zajímá, jaká konfigurace je nejrychlejší. Z výše vykresleného grafu můžeme vyloučit některé konfigurace. Existuje tam však minimálně jedna dvojice, u které nedokážeme jednoznačně určit, která je lepší - pokud nebudeme porovnávat pouze extrémní hodnoty, které mohou být dané náhodou, ale celkově. Proto proveďte vhodný test významnosti - v následující části diskutujte zejména rozložení dat (i s odkazem na předchozí buňky, variabilitu vs polohu a podobně). Je nutné každý logický krok a výběry statistických funkcí komentovat. \n",
    "\n",
    "Vužijte vhodnou funkci z knihovny `scipy.stats` a funkci poté __implementujte sami__ na základě základních matematických funkcí knihovny `numpy` případně i funkcí pro výpočet vybraného rozložení v [scipy.stats](https://docs.scipy.org/doc/scipy/reference/stats.html). Při vlastní implementaci není nutné se primárně soustředit na efektivitu výpočtu (není potřeba využít všechny funkce numpy, můžete použít normální cykly a podobně - v hodnocení však bude zahrnuta přehlednost a neměly by se objevit jasné chyby, jako je zvýšení třídy složitosti a podobně)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__OTÁZKA K DOPLNĚNÍ:__\n",
    "\n",
    "_Jaká data budete zkoumat? Jaké mají rozložení a parametry (např. varianci) a jaký test použijete? Jaká je nulová hypotéza? Jak se liší variabilita a poloha vybraných konfigurací?_\n",
    "\n",
    "Zkoumat se budou běhy jednotlivých konfigurací algoritmů. Jejich rozložení je nejprve nutno zjistit. Podle prvotního odhadu by se mohlo jednat o normální rozdělení, což lze vyzkoumat pomocí p-hodnot Shapiro–Wilk testu a dále ověřit vizuálně pomocí histogramu. Pro porovnání 2 konfigurací s normálním rozložením je vhodný dvouvýběrový Studentův t-test. Prvně ale musíme určit, zda jsou dat závislá, či nezávislá. V zadání je napsáno \"budete analyzovat časy běhu šesti různých konfigurací algoritmů\", z čehož je vyvodit, že data jsou nezívislá, jelikož se neprovádělo měření nad jedním algoritmem, ale nad více algoritmy. Data tedy musí být analyzována nepárovým t-testem.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Hypotézy budou stanoveny následovně:\n",
    "- $H_0$: Obě porovnávané konfigurace mají stejný průměr\n",
    "- $H_1$: Obě porovnávané konfigurace mají různý průměr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data for each configuration\n",
    "data_dict = df.groupby('configuration')['runtime'].apply(np.array).to_dict()\n",
    "\n",
    "# create subplots\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(12, 8)) \n",
    "axes_lin = axes.reshape(-1)\n",
    "\n",
    "# check if data have normal distribution\n",
    "for index, (config, data) in enumerate(data_dict.items()):\n",
    "    # Shapiro–Wilk test\n",
    "    stat, p_value = stats.shapiro(data)\n",
    "    print(f'{config}: p-hodnota = {p_value}')\n",
    "    \n",
    "    # histogram with Gaussian curve\n",
    "    sns.histplot(data, kde=True, stat=\"density\", bins=30, color='blue', ax=axes_lin[index])\n",
    "    axes_lin[index].set_xlabel('Hodnoty')\n",
    "    axes_lin[index].set_ylabel('Hustota')\n",
    "    axes_lin[index].set_title(config)\n",
    "\n",
    "# show plot\n",
    "fig.suptitle(f'Histogramy s Gaussovou křivkou')\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# compare all configurations\n",
    "results = []\n",
    "for index, (config1, data1) in enumerate(data_dict.items()):\n",
    "    for config2, data2 in list(data_dict.items()):\n",
    "        if config1 == config2:\n",
    "            continue\n",
    "        t_stat, _ = stats.ttest_ind(data1, data2, equal_var=False)\n",
    "        results.append({'A': config1, 'B': config2, 't_stat': t_stat})\n",
    "\n",
    "# compare results and order algorithms by results\n",
    "rdf = pd.DataFrame(results)\n",
    "# count number of positive 't_stat' values (== how many configurations are better than current)\n",
    "find_order = lambda x: f\"{len(list(filter(lambda y: y >= 0, x))) + 1}. fastest\" \n",
    "tmp_data = rdf.groupby('A')['t_stat'].apply(find_order).sort_values()\n",
    "# show as dataframe\n",
    "pd.DataFrame({'Configuration': tmp_data.keys(), 'Order': tmp_data.values})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__OTÁZKA K DOPLNĚNÍ:__\n",
    "\n",
    "_Jaký je závěr statistického testu?_\n",
    "\n",
    "Nejrychlejší konfigurce je konfigurace s označením 'config1'.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vlastní implementace\n",
    "Implementujte stejný test pomocí knihovních funkcí a ukažte, že je výsledek stejný."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# TODO vlastni implementace zvoleneho testu\n",
    "\n",
    "def independent_t_test(x1: np.ndarray, x2: np.ndarray) -> float:\n",
    "    \n",
    "    # 1/(N-1) * SUM((x_i-x_mean)^2)\n",
    "    def std_squared(x: np.ndarray, mean: float) -> None:\n",
    "        # sum 'insides'\n",
    "        tmp = [(xi - mean)**2 for xi in x]\n",
    "        \n",
    "        # sum\n",
    "        tmp_sum = sum(tmp)\n",
    "        \n",
    "        # divide by (count-1)\n",
    "        return tmp_sum/(len(x)-1)\n",
    "    \n",
    "    \n",
    "    x1_mean = x1.mean()\n",
    "    x2_mean = x2.mean()\n",
    "    \n",
    "    std_1_squared = std_squared(x1, x1_mean)\n",
    "    std_2_squared = std_squared(x2, x2_mean)\n",
    "    \n",
    "    d = (x1_mean-x2_mean)/(((std_1_squared/len(x1))+(std_2_squared/len(x2)))**(1/2))\n",
    "    return d\n",
    "    \n",
    "    \n",
    "independent_t_test(np.array(data_dict['config1']), np.array(data_dict['config2']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run independent t-test for every configuration pair\n",
    "rdf['custom_t_stat'] = rdf.apply(lambda row: independent_t_test(data_dict[row['A']], data_dict[row['B']]), axis=1)\n",
    "\n",
    "# compare custom t-test result with scipy t-test result\n",
    "rdf['comparation'] = rdf.apply(lambda row: abs(row['custom_t_stat'] - row['t_stat']) < 1e-9, axis=1)\n",
    "rdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
